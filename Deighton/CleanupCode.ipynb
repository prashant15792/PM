{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e092e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5800ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class file_cleanup:\n",
    "    def preprocess_file(po_file_path):\n",
    "        for file_name in(glob.glob(po_file_path+\"\\\\*.csv\")):\n",
    "            file= file_name\n",
    "            df = pd.read_csv(file)\n",
    "            df.dropna(subset = ['event_type'], inplace = True)\n",
    "            df['context_week_period'].replace(['WEEK', 'WEEKEND'],[0, 1], inplace=True)\n",
    "            df['context_weather_simplified'].replace(['DRY', 'RAIN'],[0, 1], inplace=True)\n",
    "            df['context_solar_condition_simplified'].replace(['NIGHT'],[0], inplace=True)\n",
    "            df['event_type'].replace(['BRAKING', 'ACCEL'],[0,1], inplace=True)\n",
    "            df['event_level'].replace(['MEDIUM'],[0], inplace=True)\n",
    "            df['country_code'].replace(['US'],[0], inplace=True)\n",
    "            df['country_name'].replace(['United States of America'],[0], inplace=True)\n",
    "            df['department_or_county_name'].replace(['Weber', 'Salt Lake', 'Utah', 'Davis', 'Cache', 'Sevier',\n",
    "       'Box Elder', 'Juab', 'Piute', 'Kane', 'Sanpete', 'Morgan', 'Wayne',\n",
    "       'Summit', 'Garfield', 'Wasatch', 'Rich', 'Emery', 'Carbon',\n",
    "       'Duchesne', 'Grand', 'San Juan', 'Uintah', 'Daggett', 'Millard',\n",
    "       'Washington', 'Iron', 'Beaver', 'Tooele'],[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28], inplace=True)\n",
    "            df['city_name'].replace(['Ogden--Layton, UT', 'Salt Lake City--West Valley City, UT', \n",
    "       'Provo--Orem, UT', 'Logan, UT', 'Santaquin, UT', 'Nephi, UT',\n",
    "       'Gunnison, UT', 'Morgan, UT', 'Manti, UT', 'Summit Park, UT',\n",
    "       'Ephraim, UT', 'Park City, UT', 'Heber, UT', 'Mount Pleasant, UT',\n",
    "       'Kamas, UT', 'Castle Dale, UT', 'Price, UT', 'Roosevelt, UT',\n",
    "       'Vernal, UT', 'Moab, UT', 'Blanding, UT', 'St. George, UT',\n",
    "       'Hurricane, UT', 'Cedar City, UT', 'Parowan, UT', 'Beaver, UT',\n",
    "       'Delta, UT', 'Kanab, UT', 'Grantsville, UT', 'Tooele, UT',\n",
    "       'Stansbury Park, UT', 'Tremonton, UT', 'Richfield, UT',\n",
    "       'Eagle Mountain South, UT', 'Colorado City, AZ--UT',\n",
    "       'West Wendover, NV--UT'],[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35], inplace=True)\n",
    "            df['state'].replace(['Utah'],[0], inplace=True)\n",
    "            df['state_id'].replace(['UT'],[0], inplace=True)\n",
    "            \n",
    "            \n",
    "            csv_data = df.to_csv()\n",
    "            with open(file, 'w') as csv_file:\n",
    "                df.to_csv(file,line_terminator='\\n')\n",
    "                print('Pre-processing completed for-Removed Records with No Event Type-'+file.replace(po_file_path+'\\\\',''))\n",
    "            \n",
    "            \n",
    "            \n",
    "    def p_extract_files(pi_file_patch, po_file_path):\n",
    "        file=''\n",
    "        for file_name in(glob.glob(pi_file_patch+\"\\\\*.zip\")):\n",
    "            try :\n",
    "                file= file_name.replace(pi_file_patch+\"\\\\\",'')\n",
    "                with ZipFile(pi_file_patch+'\\\\'+file, 'r') as myzip:\n",
    "                    myzip.extractall(po_file_path)\n",
    "                    print('Extraction Completed for -'+file)\n",
    "            except RuntimeError as er :\n",
    "                print(f\" Bad ZIP found -> {er} \"+file)   # <-- JUMP TO HERE IF BadZipFile exception\n",
    "                continue\n",
    "                \n",
    "    def p_start_cleanup(pi_file_patch, po_file_path):\n",
    "        p_extract_files(pi_file_patch, po_file_path)\n",
    "        preprocess_file(po_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca0b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Completed for -2019-11.zip\n",
      " Bad ZIP found -> That compression method is not supported 2019-12.zip\n",
      " Bad ZIP found -> That compression method is not supported 2020-1.zip\n",
      "Extraction Completed for -2020-12.zip\n",
      "Extraction Completed for -2020-2.zip\n",
      "Extraction Completed for -2021-1.zip\n",
      "Extraction Completed for -2021-12.zip\n",
      "Extraction Completed for -2021-2.zip\n",
      "Extraction Completed for -2022-1.zip\n",
      "Extraction Completed for -2022-2.zip\n"
     ]
    }
   ],
   "source": [
    "file_cleanup.p_extract_files(r\"C:\\Users\\Prashant Mishra\\Desktop\\Durham College\\AI HUB\\Deighton\\Telematics\",r\"C:\\Users\\Prashant Mishra\\Desktop\\Durham College\\AI HUB\\Deighton\\Telematics\\Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19896a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2019-11.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2020-12.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2020-2.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2021-1.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2021-12.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2021-2.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2022-1.csv\n",
      "Pre-processing completed for-Removed Records with No Event Type-period_id=2022-2.csv\n"
     ]
    }
   ],
   "source": [
    "file_cleanup.preprocess_file(r\"C:\\Users\\Prashant Mishra\\Desktop\\Durham College\\AI HUB\\Deighton\\Telematics\\Output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
