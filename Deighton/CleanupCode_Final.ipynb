{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ec8131",
   "metadata": {},
   "source": [
    "Installing zipfile_deflate64 librabry for as Windows' in-built compression module uses Deflate64  compression method for file with size over 2GB which is not supported by conventional uncompression python libraries like Zipfile and pyzipper\n",
    "https://github.com/brianhelba/zipfile-deflate64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abfeeabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipfile_deflate64 in c:\\anaconda\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install zipfile_deflate64  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder is used to normalize labels. It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile_deflate64  as ZipFile\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59209a",
   "metadata": {},
   "source": [
    "glob:\n",
    "It is a powerful tool in Python to help with file management and filtering. \n",
    "glob helps to filter through large datasets and pull out only files that are of interest \n",
    "\n",
    "LabelEncoder :\n",
    "It is used to normalize labels. \n",
    "It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa672729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class file_cleanup:\n",
    "    def preprocess_file(po_file_path):\n",
    "        le = LabelEncoder()\n",
    "        for file_name in(glob.glob(po_file_path+\"\\\\*.csv\")):\n",
    "            file= file_name\n",
    "            print('Pre-processing Starting for-'+file.replace(po_file_path+'\\\\',''))\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            df.dropna(subset = ['event_type'], inplace = True)\n",
    "            df['context_week_period'] = le.fit_transform(df['context_week_period'])\n",
    "            df['context_weather_simplified'] = le.fit_transform(df['context_weather_simplified'])\n",
    "            df['context_solar_condition_simplified'] = le.fit_transform(df['context_solar_condition_simplified'])\n",
    "            df['event_type'] = le.fit_transform(df['event_type'])\n",
    "            df['event_level'] = le.fit_transform(df['event_level'])\n",
    "            df['country_code'] = le.fit_transform(df['country_code'])\n",
    "            df['country_name'] = le.fit_transform(df['country_name'])\n",
    "            df['department_or_county_name'] = le.fit_transform(df['department_or_county_name'])\n",
    "            df['city_name'] = le.fit_transform(df['city_name'])\n",
    "            df['state'] = le.fit_transform(df['state'])            \n",
    "            df['state_id'] = le.fit_transform(df['state_id'])\n",
    "            if 'interaction_poi_type' in df.columns:\n",
    "                df['interaction_poi_type'] = le.fit_transform(df['interaction_poi_type'])\n",
    "            if 'circulation_poi_type' in df.columns:\n",
    "                df['circulation_poi_type'] = le.fit_transform(df['circulation_poi_type'])            \n",
    "            \n",
    "            csv_data = df.to_csv()\n",
    "            with open(file, 'w') as csv_file:\n",
    "                df.to_csv(file,line_terminator='\\n')\n",
    "                print('Pre-processing completed for-'+file.replace(po_file_path+'\\\\',''))\n",
    "            \n",
    "            \n",
    "            \n",
    "    def p_extract_files(pi_file_patch, po_file_path):\n",
    "        file=''\n",
    "        for file_name in(glob.glob(pi_file_patch+\"\\\\*.zip\")):\n",
    "            try :\n",
    "                file= file_name.replace(pi_file_patch+\"\\\\\",'')\n",
    "                with ZipFile.ZipFile(pi_file_patch+'\\\\'+file, 'r') as myzip:\n",
    "                    myzip.extractall(po_file_path)\n",
    "                    print('Extraction Completed for -'+file)\n",
    "            except RuntimeError as er :\n",
    "                print(f\" Bad ZIP found -> {er} \"+file)   # <-- JUMP TO HERE IF BadZipFile exception\n",
    "                continue\n",
    "                \n",
    "    def p_start_cleanup(pi_file_patch, po_file_path):\n",
    "        file_cleanup.p_extract_files(pi_file_patch, po_file_path)\n",
    "        file_cleanup.preprocess_file(po_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21efe04",
   "metadata": {},
   "source": [
    "Class file_cleanup three memeber functions:\n",
    "    1) p_start_cleanup - Master member function which takes two parameters i) Input File Path ii) Output file path\n",
    "    2) p_extract_files - Public member function of the class which is executed to identify the zip files on input path \n",
    "                         , unzip it and place the unzipped files on the output file path.\n",
    "                         It accepts two parameters i) Input File Path ii) Output file path\n",
    "    3) preprocess_file - Public member of the class which is executed to read the CSV files available on output file path, \n",
    "                         perform data cleansing and replace the files on output file path with cleaned up files.\n",
    "    \n",
    "    \n",
    "    Files are supposed to be cleaned as below:\n",
    "         Records with No data in 'event_type' will be dropped.\n",
    "         Label encoding for categorical values in below mentioned fields:\n",
    "         1)  context_week_period\n",
    "         2)  context_weather_simplified\n",
    "         3)  context_solar_condition_simplified\n",
    "         4)  event_type\n",
    "         5)  event_level\n",
    "         6)  country_code\n",
    "         7)  country_name\n",
    "         8)  department_or_county_name\n",
    "         9)  city_name\n",
    "         10) state\n",
    "         11) state_id\n",
    "         12) interaction_poi_type\n",
    "         13) circulation_poi_type \n",
    "                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e8a893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Completed for -2019-11.zip\n",
      "Extraction Completed for -2019-12.zip\n",
      "Extraction Completed for -2020-1.zip\n",
      "Extraction Completed for -2020-12.zip\n",
      "Extraction Completed for -2020-2.zip\n",
      "Extraction Completed for -2021-1.zip\n",
      "Extraction Completed for -2021-12.zip\n",
      "Extraction Completed for -2021-2.zip\n",
      "Extraction Completed for -2022-1.zip\n",
      "Extraction Completed for -2022-2.zip\n",
      "Pre-processing Starting for-period_id=2019-11.csv\n",
      "Pre-processing completed for-period_id=2019-11.csv\n",
      "Pre-processing Starting for-period_id=2019-12.csv\n",
      "Pre-processing completed for-period_id=2019-12.csv\n",
      "Pre-processing Starting for-period_id=2020-1.csv\n",
      "Pre-processing completed for-period_id=2020-1.csv\n",
      "Pre-processing Starting for-period_id=2020-12.csv\n",
      "Pre-processing completed for-period_id=2020-12.csv\n",
      "Pre-processing Starting for-period_id=2020-2.csv\n",
      "Pre-processing completed for-period_id=2020-2.csv\n",
      "Pre-processing Starting for-period_id=2021-1.csv\n",
      "Pre-processing completed for-period_id=2021-1.csv\n",
      "Pre-processing Starting for-period_id=2021-12.csv\n",
      "Pre-processing completed for-period_id=2021-12.csv\n",
      "Pre-processing Starting for-period_id=2021-2.csv\n",
      "Pre-processing completed for-period_id=2021-2.csv\n",
      "Pre-processing Starting for-period_id=2022-1.csv\n",
      "Pre-processing completed for-period_id=2022-1.csv\n",
      "Pre-processing Starting for-period_id=2022-2.csv\n",
      "Pre-processing completed for-period_id=2022-2.csv\n"
     ]
    }
   ],
   "source": [
    "file_cleanup.p_start_cleanup( r\"C:\\Users\\Prashant Mishra\\Desktop\\Durham College\\AI HUB\\Deighton\\Telematics\",r\"C:\\Users\\Prashant Mishra\\Desktop\\Durham College\\AI HUB\\Deighton\\Telematics\\OUTPUT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
